{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import openai\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"ðŸ”‘ Enter your OpenAI API key: \")\n",
    "openai.api_key = openai_api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from phoenix.trace import TraceDataset, using_project\n",
    "\n",
    "\n",
    "# Display the complete contents of dataframe cells.\n",
    "# pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_hex = \"6d71d4a4-55cf-4222-a084-b988481f296b\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with using_project(\"ragas-testset\"):\n",
    "    trace_dataset = TraceDataset.load(testset_hex, directory='./data')\n",
    "    session = px.launch_app(trace=trace_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "dir_path = \"./data/prompt-engineering-papers\"\n",
    "reader = SimpleDirectoryReader(dir_path, num_files_limit=2)\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set handler for `Llama Index` and `Langchain`(Ragas uses Langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import set_global_handler\n",
    "from phoenix.trace.langchain import LangChainInstrumentor\n",
    "\n",
    "\n",
    "# Setup instrumentation for both llama-index and LangChain (used by Ragas)\n",
    "set_global_handler(\"arize_phoenix\")\n",
    "LangChainInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from phoenix.trace import using_project\n",
    "\n",
    "\n",
    "def build_query_engine(documents):\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        embed_model=OpenAIEmbedding(),\n",
    "    )\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=2)\n",
    "    return query_engine\n",
    "\n",
    "\n",
    "with using_project(\"indexing\"):\n",
    "    # By assigning a project name, the instrumentation will send all the embeddings to the indexing project\n",
    "    query_engine = build_query_engine(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_traces = px.Client().get_trace_dataset(project_name=\"indexing\").save(directory=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_traces.hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.Client().query_spans(project_name=\"indexing\").head(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.Client().query_spans(project_name=\"indexing\")[\"attributes.embedding.embeddings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings to dataframe for use in visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.trace.dsl.helpers import SpanQuery\n",
    "\n",
    "client = px.Client()\n",
    "corpus_df = px.Client().query_spans(\n",
    "    SpanQuery().explode(\n",
    "        \"embedding.embeddings\",\n",
    "        text=\"embedding.text\",\n",
    "        vector=\"embedding.vector\",\n",
    "    ),\n",
    "    project_name=\"indexing\",\n",
    ")\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"./data/{testset_hex}-testset.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from phoenix.trace import using_project\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def generate_response(query_engine, question):\n",
    "    response = query_engine.query(question)\n",
    "    return {\n",
    "        \"answer\": response.response,\n",
    "        \"contexts\": [c.node.get_content() for c in response.source_nodes],\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_ragas_dataset(query_engine, test_df):\n",
    "    test_questions = test_df[\"question\"].values\n",
    "    responses = [generate_response(query_engine, q) for q in tqdm(test_questions)]\n",
    "\n",
    "    dataset_dict = {\n",
    "        \"question\": test_questions,\n",
    "        \"answer\": [response[\"answer\"] for response in responses],\n",
    "        \"contexts\": [response[\"contexts\"] for response in responses],\n",
    "        \"ground_truth\": test_df[\"ground_truth\"].values.tolist(),\n",
    "    }\n",
    "    ds = Dataset.from_dict(dataset_dict)\n",
    "    return ds\n",
    "\n",
    "\n",
    "with using_project(\"llama-index\"):\n",
    "    ragas_eval_dataset = generate_ragas_dataset(query_engine, test_df)\n",
    "\n",
    "ragas_evals_df = pd.DataFrame(ragas_eval_dataset)\n",
    "ragas_evals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
