{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "# from dspy.retrieve.weaviate_rm import WeaviateRM\n",
    "from dspy.retrieve.pgvector_rm import PgVectorRM\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "# import weaviate\n",
    "# import weaviate.classes as wvc\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions \n",
    "import fnmatch\n",
    "import uuid\n",
    "import torch\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "import re\n",
    "from dspy.evaluate.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn_string = f\"postgresql://daybreak:daybreak@localhost:5432/daybreak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = psycopg2.connect(conn_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add pgvector extension and create test table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with conn.cursor() as cur:\n",
    "#     cur.execute('CREATE EXTENSION IF NOT EXISTS vector')\n",
    "#     register_vector(conn)\n",
    "#     cur.execute(\"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS text(\n",
    "#         id SERIAL PRIMARY KEY,\n",
    "#         text TEXT\n",
    "#         );\n",
    "#     \"\"\")\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_md_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, '*.md'):\n",
    "                filename = os.path.join(root, basename)\n",
    "                yield filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in find_md_files(\"./repos\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = [filename for filename in find_md_files(\"./repos\")] \n",
    "doc_contents = []\n",
    "for doc in find_md_files(\"./repos\"):\n",
    "    with open(doc, 'r') as f:\n",
    "        doc_contents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = \"\".join(doc_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_splitter.split_text(all_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = text_splitter.split_text(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up local llm and retriever client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = dspy.OllamaLocal(\"zephyr-7b-beta\", max_tokens=3000, stop=['\\n\\n'], model_type=\"chat\")\n",
    "llm = dspy.OllamaLocal(\"open-hermes-2-4_0\", max_tokens=3000, model_type=\"chat\")\n",
    "chroma_client = client = chromadb.PersistentClient(path=\"./chroma\")\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "collection = chroma_client.get_or_create_collection(name=\"docs\", embedding_function=default_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=docs)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.add(ids=[str(uuid.uuid4()) for _ in range(len(split_docs))], documents=split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model = ChromadbRM(\"docs\", \"./chroma\", embedding_function=default_ef, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=llm, rm=retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hello! I'm doing well, thank you for asking. How can I assist you today?\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"hi how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = requests.get('https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json')\n",
    "# data = json.loads(resp.text)  \n",
    "\n",
    "# question_objs = list()\n",
    "# for i, d in enumerate(data):\n",
    "#     question_objs.append({\n",
    "#         \"answer\": d[\"Answer\"],\n",
    "#         \"question\": d[\"Question\"],\n",
    "#         \"category\": d[\"Category\"],\n",
    "\n",
    "# questions = weaviate_client.collections.get(\"Question\")\n",
    "# questions.data.insert_many(question_objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionToBlogOutline(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Your task is to write a blog post that will help answer the given question. \n",
    "    Please use the contexts to evaluate the structure of the blog post.\n",
    "    \"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    context = dspy.InputField()\n",
    "    blog_outline = dspy.OutputField(desc=\"A comma separated list of topics. IMPORTANT!! ONLY SEPARATE TOPICS WITH A COMMA!! ONLY OUTPUT THE TOPICS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection.get(include=['embeddings'])['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_question = \"What is DSPy used for?\"\n",
    "ex_context = dspy.Retrieve(k=5)(ex_question).passages\n",
    "ex_context = \"\".join(ex_context)\n",
    "cot = dspy.ChainOfThought(QuestionToBlogOutline)(question=ex_question, context=ex_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    rationale='write a blog post that will help answer the given question. We need to understand what DSPy is used for, consider its differences from other libraries and frameworks, discuss how much data is needed and how to collect it, and finally, explore other DSPy modules and their usage.',\n",
       "    blog_outline='Differences between DSPy and other libraries, Data requirements and collection, DSPy Modules'\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Your task is to write a blog post that will help answer the given question. \n",
      "    Please use the contexts to evaluate the structure of the blog post.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Context: ${context}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the blog_outline}. We ...\n",
      "\n",
      "Blog Outline: A comma separated list of topics. IMPORTANT!! ONLY SEPARATE TOPICS WITH A COMMA!! ONLY OUTPUT THE TOPICS\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is DSPy used for?\n",
      "\n",
      "Context:\n",
      "'re willing to implement (or extend) your own short program. In short, **DSPy** is for when you need a lightweight but automatically-optimizing programming model — not a library of predefined prompts and integrations. If you're familiar with neural networks: This is like the difference between PyTorch (i.e., representing **DSPy**) and HuggingFace Transformers (i.e., representing the higher-level libraries).\n",
      "\n",
      "**DSPy vs to the API References for DSPy! This is where you'll find easy-to-understand information about all the parts of DSPy that you can use in your projects. We've got guides on different tools and helpers that DSPy has, like modules and optimizers. Everything is sorted so you can quickly find what you need. If you're making something and need to quickly get started with DSPy to do certain tasks, this place will show you how to set it Data\n",
      "\n",
      "DSPy is a machine learning framework, so working in it involves training sets, development sets, and test sets.\n",
      "\n",
      "For each example in your data, we distinguish typically between three types of values: the inputs, the intermediate labels, and the final label. You can use DSPy effectively without any intermediate or final labels, but you will need at least a few example inputs.\n",
      "\n",
      "## How much data do I need and how do I collect data for my tasky** philosophy and abstraction differ significantly from other libraries and frameworks, so it's usually straightforward to decide when **DSPy** is (or isn't) the right framework for your usecase. If you're a NLP/AI researcher (or a practitioner exploring new pipelines or new tasks), the answer is generally an invariable **yes**. If you're a practitioner doing other things, please read on.\n",
      "\n",
      "**DSPy vs. thin wrappers for prompts (OpenAI`\n",
      "\n",
      "\n",
      "## What other DSPy modules are there? How can I use them?\n",
      "\n",
      "The others are very similar. They mainly change the internal behavior with which your signature is implemented!\n",
      "\n",
      "1. **`dspy.Predict`**: Basic predictor. Does not modify the signature. Handles the key forms of learning (i.e., storing the instructions and demonstrations and updates to the LM).\n",
      "\n",
      "2. **`dspy.ChainOfTh\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m write a blog post that will help answer the given question. We need to understand what DSPy is used for, consider its differences from other libraries and frameworks, discuss how much data is needed and how to collect it, and finally, explore other DSPy modules and their usage.\n",
      "\n",
      "Blog Outline: \n",
      "Differences between DSPy and other libraries, Data requirements and collection, DSPy Modules\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'re willing to implement (or extend) your own short program. In short, **DSPy** is for when you need a lightweight but automatically-optimizing programming model — not a library of predefined prompts and integrations. If you're familiar with neural networks: This is like the difference between PyTorch (i.e., representing **DSPy**) and HuggingFace Transformers (i.e., representing the higher-level libraries).\\n\\n**DSPy vs to the API References for DSPy! This is where you'll find easy-to-understand information about all the parts of DSPy that you can use in your projects. We've got guides on different tools and helpers that DSPy has, like modules and optimizers. Everything is sorted so you can quickly find what you need. If you're making something and need to quickly get started with DSPy to do certain tasks, this place will show you how to set it Data\\n\\nDSPy is a machine learning framework, so working in it involves training sets, development sets, and test sets.\\n\\nFor each example in your data, we distinguish typically between three types of values: the inputs, the intermediate labels, and the final label. You can use DSPy effectively without any intermediate or final labels, but you will need at least a few example inputs.\\n\\n## How much data do I need and how do I collect data for my tasky** philosophy and abstraction differ significantly from other libraries and frameworks, so it's usually straightforward to decide when **DSPy** is (or isn't) the right framework for your usecase. If you're a NLP/AI researcher (or a practitioner exploring new pipelines or new tasks), the answer is generally an invariable **yes**. If you're a practitioner doing other things, please read on.\\n\\n**DSPy vs. thin wrappers for prompts (OpenAI`\\n\\n\\n## What other DSPy modules are there? How can I use them?\\n\\nThe others are very similar. They mainly change the internal behavior with which your signature is implemented!\\n\\n1. **`dspy.Predict`**: Basic predictor. Does not modify the signature. Handles the key forms of learning (i.e., storing the instructions and demonstrations and updates to the LM).\\n\\n2. **`dspy.ChainOfTh\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Differences, Data Collection, Modules'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot = dspy.ChainOfThought(QuestionToBlogOutline)\n",
    "cot(question=ex_question, context=ex_context).blog_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChainOfThought(QuestionToBlogOutline(question, context -> blog_outline\n",
       "    instructions='\\n    Your task is to write a blog post that will help answer the given question. \\n    Please use the contexts to evaluate the structure of the blog post.\\n    '\n",
       "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
       "    context = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Context:', 'desc': '${context}'})\n",
       "    blog_outline = Field(annotation=str required=True json_schema_extra={'desc': 'A comma separated list of topics. IMPORTANT!! ONLY SEPARATE TOPICS WITH A COMMA!! ONLY OUTPUT THE TOPICS', '__dspy_field_type': 'output', 'prefix': 'Blog Outline:'})\n",
       "))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'long_text': \"'re willing to implement (or extend) your own short program. In short, **DSPy** is for when you need a lightweight but automatically-optimizing programming model — not a library of predefined prompts and integrations. If you're familiar with neural networks: This is like the difference between PyTorch (i.e., representing **DSPy**) and HuggingFace Transformers (i.e., representing the higher-level libraries).\\n\\n**DSPy vs\"},\n",
       " {'long_text': ' Data\\n\\nDSPy is a machine learning framework, so working in it involves training sets, development sets, and test sets.\\n\\nFor each example in your data, we distinguish typically between three types of values: the inputs, the intermediate labels, and the final label. You can use DSPy effectively without any intermediate or final labels, but you will need at least a few example inputs.\\n\\n## How much data do I need and how do I collect data for my task'},\n",
       " {'long_text': \"y** philosophy and abstraction differ significantly from other libraries and frameworks, so it's usually straightforward to decide when **DSPy** is (or isn't) the right framework for your usecase. If you're a NLP/AI researcher (or a practitioner exploring new pipelines or new tasks), the answer is generally an invariable **yes**. If you're a practitioner doing other things, please read on.\\n\\n**DSPy vs. thin wrappers for prompts (OpenAI\"},\n",
       " {'long_text': \" to the API References for DSPy! This is where you'll find easy-to-understand information about all the parts of DSPy that you can use in your projects. We've got guides on different tools and helpers that DSPy has, like modules and optimizers. Everything is sorted so you can quickly find what you need. If you're making something and need to quickly get started with DSPy to do certain tasks, this place will show you how to set it\"},\n",
       " {'long_text': 'xiv.org/abs/2310.03714) | N/A | Sections 3, 5, 6, and 7 of the DSPy paper can be consumed as a tutorial. They include explained code snippets, results, and discussions of the abstractions and API.\\n| Intermediate | [**DSPy Assertions**](https://arxiv.org/abs/2312.13382) | [<img align=\"center\" src=\"https://'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_model(\"What is dspy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Your task is to write a blog post that will help answer the given question. \n",
      "    Please use the contexts to evaluate the structure of the blog post.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Context: ${context}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the blog_outline}. We ...\n",
      "\n",
      "Blog Outline: A comma separated list of topics. IMPORTANT!! ONLY SEPARATE TOPICS WITH A COMMA!! ONLY OUTPUT THE TOPICS\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is DSPy used for?\n",
      "\n",
      "Context:\n",
      "'re willing to implement (or extend) your own short program. In short, **DSPy** is for when you need a lightweight but automatically-optimizing programming model — not a library of predefined prompts and integrations. If you're familiar with neural networks: This is like the difference between PyTorch (i.e., representing **DSPy**) and HuggingFace Transformers (i.e., representing the higher-level libraries).\n",
      "\n",
      "**DSPy vs to the API References for DSPy! This is where you'll find easy-to-understand information about all the parts of DSPy that you can use in your projects. We've got guides on different tools and helpers that DSPy has, like modules and optimizers. Everything is sorted so you can quickly find what you need. If you're making something and need to quickly get started with DSPy to do certain tasks, this place will show you how to set it Data\n",
      "\n",
      "DSPy is a machine learning framework, so working in it involves training sets, development sets, and test sets.\n",
      "\n",
      "For each example in your data, we distinguish typically between three types of values: the inputs, the intermediate labels, and the final label. You can use DSPy effectively without any intermediate or final labels, but you will need at least a few example inputs.\n",
      "\n",
      "## How much data do I need and how do I collect data for my tasky** philosophy and abstraction differ significantly from other libraries and frameworks, so it's usually straightforward to decide when **DSPy** is (or isn't) the right framework for your usecase. If you're a NLP/AI researcher (or a practitioner exploring new pipelines or new tasks), the answer is generally an invariable **yes**. If you're a practitioner doing other things, please read on.\n",
      "\n",
      "**DSPy vs. thin wrappers for prompts (OpenAI`\n",
      "\n",
      "\n",
      "## What other DSPy modules are there? How can I use them?\n",
      "\n",
      "The others are very similar. They mainly change the internal behavior with which your signature is implemented!\n",
      "\n",
      "1. **`dspy.Predict`**: Basic predictor. Does not modify the signature. Handles the key forms of learning (i.e., storing the instructions and demonstrations and updates to the LM).\n",
      "\n",
      "2. **`dspy.ChainOfTh\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m write a blog post that will help answer the given question. We need to understand what DSPy is used for, consider its differences from other libraries and frameworks, discuss how much data is needed and how to collect it, and finally, explore other DSPy modules and their usage.\n",
      "\n",
      "Blog Outline: Differences, Data Collection, Modules\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicToParagraph(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Your task it to write a paragraph that explains a topic based on the retrieved contexts.\n",
    "    \"\"\"\n",
    "\n",
    "    topic = dspy.InputField(desc=\"A topic to write a paragraph about based on the information given.\")\n",
    "    context = dspy.InputField(desc=\"contains relevant information about the topic.\")\n",
    "    paragraph = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DSPy is a lightweight and automatically-optimizing programming model that enables users to implement their own short programs. It offers a lower-level approach compared to higher-level libraries like HuggingFace Transformers, similar to PyTorch. The API References for DSPy provide comprehensive guides on various tools and helpers, including modules and optimizers, organized for easy access. This makes it an ideal choice when you need a lightweight programming model with automatic optimization capabilities.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_topic = \"An Overview of DSPy's features.\"\n",
    "ex_topic_context = dspy.Retrieve(k=5)(ex_topic).passages\n",
    "ex_topic_context = \"\".join(ex_topic_context)\n",
    "dspy.ChainOfThought(TopicToParagraph)(topic=ex_topic, context=ex_topic_context).paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Your task it to write a paragraph that explains a topic based on the retrieved contexts.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Topic: A topic to write a paragraph about based on the information given.\n",
      "\n",
      "Context: contains relevant information about the topic.\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the paragraph}. We ...\n",
      "\n",
      "Paragraph: ${paragraph}\n",
      "\n",
      "---\n",
      "\n",
      "Topic: An Overview of DSPy's features.\n",
      "\n",
      "Context:\n",
      "'re willing to implement (or extend) your own short program. In short, **DSPy** is for when you need a lightweight but automatically-optimizing programming model — not a library of predefined prompts and integrations. If you're familiar with neural networks: This is like the difference between PyTorch (i.e., representing **DSPy**) and HuggingFace Transformers (i.e., representing the higher-level libraries).\n",
      "\n",
      "**DSPy vs to the API References for DSPy! This is where you'll find easy-to-understand information about all the parts of DSPy that you can use in your projects. We've got guides on different tools and helpers that DSPy has, like modules and optimizers. Everything is sorted so you can quickly find what you need. If you're making something and need to quickly get started with DSPy to do certain tasks, this place will show you how to set itxiv.org/abs/2310.03714) | N/A | Sections 3, 5, 6, and 7 of the DSPy paper can be consumed as a tutorial. They include explained code snippets, results, and discussions of the abstractions and API.\n",
      "| Intermediate | [**DSPy Assertions**](https://arxiv.org/abs/2312.13382) | [<img align=\"center\" src=\"https:// need and how do I collect data for my task?\n",
      "\n",
      "Concretely, you can use DSPy optimizers usefully with as few as 10 example inputs, but having 50-100 examples (or even better, 300-500 examples) goes a long way.\n",
      "\n",
      "How can you get examples like these? If your task is extremely unusual, please invest in preparing ~10 examples by hand. Often times, depending on your metric below, you just need inputs and not labels,`\n",
      "\n",
      "\n",
      "## What other DSPy modules are there? How can I use them?\n",
      "\n",
      "The others are very similar. They mainly change the internal behavior with which your signature is implemented!\n",
      "\n",
      "1. **`dspy.Predict`**: Basic predictor. Does not modify the signature. Handles the key forms of learning (i.e., storing the instructions and demonstrations and updates to the LM).\n",
      "\n",
      "2. **`dspy.ChainOfTh\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m Topic: An Overview of DSPy's features.\n",
      "\n",
      "Context: DSPy is a lightweight, automatically-optimizing programming model that allows users to implement their own short programs. It can be compared to PyTorch, which represents a lower-level approach compared to higher-level libraries like HuggingFace Transformers. The API References for DSPy provide easy-to-understand information about its tools and helpers, such as modules and optimizers, sorted for quick access.\n",
      "\n",
      "Paragraph: DSPy is a lightweight and automatically-optimizing programming model that enables users to implement their own short programs. It offers a lower-level approach compared to higher-level libraries like HuggingFace Transformers, similar to PyTorch. The API References for DSPy provide comprehensive guides on various tools and helpers, including modules and optimizers, organized for easy access. This makes it an ideal choice when you need a lightweight programming model with automatic optimization capabilities.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProofRead(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Proofread a blog post and output a more well written version of the original post.\n",
    "    \"\"\"\n",
    "\n",
    "    blog_post = dspy.InputField()\n",
    "    proofread_blog_post = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleGenerator(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Write a title for a blog post given a description of the topics the blog covers as input.\n",
    "    \"\"\"\n",
    "\n",
    "    blog_outline = dspy.InputField()\n",
    "    title = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining for iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogPostWriter(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.question_to_blog_outline = dspy.ChainOfThought(QuestionToBlogOutline)\n",
    "        self.topic_to_paragraph = dspy.ChainOfThought(TopicToParagraph)\n",
    "        self.proof_reader = dspy.ChainOfThought(ProofRead)\n",
    "        self.title_generator = dspy.ChainOfThought(TitleGenerator)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = dspy.Retrieve(k=5)(question).passages\n",
    "        context = \"\".join(context)\n",
    "        raw_blog_outline = self.question_to_blog_outline(question=question, context=context).blog_outline\n",
    "        blog_outline = raw_blog_outline.split(\",\")\n",
    "        blog = \"\"\n",
    "        for topic in blog_outline:\n",
    "            topic_contexts = dspy.Retrieve(k=5)(topic).passages\n",
    "            topic_contexts = \"\".join(topic_contexts)\n",
    "            blog += self.topic_to_paragraph(topic=topic, context=context).paragraph\n",
    "            blog += \"\\n \\n\"\n",
    "        blog = self.proof_reader(blog_post=blog).proofread_blog_post\n",
    "        title = self.title_generator(blog_outline=raw_blog_outline).title\n",
    "        final_blog = f\"{title} \\n \\n {blog}\"\n",
    "        return dspy.Prediction(blog=final_blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor '__init__' of 'super' object needs an argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dspy_topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is DSPy fopr LLMs?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m dspy_blog \u001b[38;5;241m=\u001b[39m \u001b[43mBlogPostWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(dspy_topic)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dspy_blog\u001b[38;5;241m.\u001b[39mblog)\n",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36mBlogPostWriter.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestion_to_blog_outline \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mChainOfThought(QuestionToBlogOutline)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_to_paragraph \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mChainOfThought(TopicToParagraph)\n",
      "\u001b[0;31mTypeError\u001b[0m: descriptor '__init__' of 'super' object needs an argument"
     ]
    }
   ],
   "source": [
    "dspy_topic = \"What is DSPy fopr LLMs?\"\n",
    "dspy_blog = BlogPostWriter()(dspy_topic)\n",
    "print(dspy_blog.blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.inspect_history(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Improving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogRater(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Rate a blog post on a scale of 1 to 5 based on how well written it is.\n",
    "    IMPORTANT!! ONLY OUTPUT THE RATING AS A NUMERIC FLOAT VALUE AND NOTHING ELSE!!\n",
    "    \"\"\"\n",
    "\n",
    "    blog = dspy.InputField(desc=\"a blog post\")\n",
    "    rating = dspy.OutputField(desc=\"a quality rating on a scale of 1 to 5.\")\n",
    "\n",
    "\n",
    "class MetricProgram(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rater = dspy.ChainOfThought(BlogRater)\n",
    "\n",
    "    def forward(self, gold, pred, trace=None):\n",
    "        blog = pred.blog\n",
    "        gold = gold.question\n",
    "        return float(self.rater(blog=blog).rating)\n",
    "\n",
    "def metric_wrapper(gold, pred, trace=None):\n",
    "    return MetricProgram()(gold=gold, pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy_blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.Example(question=dspy_topic).with_inputs(\"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetricProgram()(gold=dspy.Example(question=dspy_topic).with_inputs(\"question\"), pred=dspy_blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.inspect_history(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = [\n",
    "    dspy.Example(question=\"How do you set up an LM client?\").with_inputs(\"question\"),\n",
    "    dspy.Example(question=\"Can you make class based signatures?\").with_inputs(\"question\"),\n",
    "    dspy.Example(question=\"How do you create typed predictors?\").with_inputs(\"question\"),\n",
    "]\n",
    "testset = [\n",
    "    dspy.Example(question=\"What is a signature in DSPy?\").with_inputs(\"question\"),\n",
    "    dspy.Example(question=\"How does DSPy handle assertions?\").with_inputs(\"question\"),    \n",
    "    dspy.Example(question=\"What are some evaluation metrics in DSPy?\").with_inputs(\"question\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(devset=testset, num_threads=1, display_progress=True, display_table=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(BlogPostWriter(), metric=metric_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teleprompter = BootstrapFewShot(metric=metric_wrapper, max_bootstrapped_demos=1, max_rounds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_blog_writer = teleprompter.compile(BlogPostWriter(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_blog_writer.save('./data/compiled_blog_writer.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_blog_writer = BlogPostWriter()\n",
    "compiled_blog_writer.load(\"./data/compiled_blog_writer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGTM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily remove \\n\\n stop to print whole blog\n",
    "llm = dspy.OllamaLocal(\"zephyr-7b-beta\", max_tokens=3000, model_type=\"chat\")\n",
    "dspy.settings.configure(lm=llm, rm=retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compiled_blog_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtm = compiled_blog_writer(\"What is a signature?\").blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.inspect_history(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(compiled_blog_writer, metric=metric_wrapper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
