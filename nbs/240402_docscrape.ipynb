{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest Documentation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will serve as a baseline workflow for fetching the latest documentation for LLM libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get git repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# mkdir -p repos &&\n",
    "# cd repos &&\n",
    "# git clone https://github.com/krypticmouse/dspy-docs master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update submodule to latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# cd repos\n",
    "# git subtree pull https://github.com/krypticmouse/dspy-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_md_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, '*.md'):\n",
    "                filename = os.path.join(root, basename)\n",
    "                yield filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [filename for filename in find_md_files(\"./repos\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./repos/master/README.md',\n",
       " './repos/master/api/assertions.md',\n",
       " './repos/master/api/intro.md',\n",
       " './repos/master/api/language_model_clients/Mistral.md',\n",
       " './repos/master/api/language_model_clients/Databricks.md']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_contents = []\n",
    "for i in range(5):\n",
    "    with open(docs[i], 'r') as f:\n",
    "        doc_contents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# DSPy Documentation\\n\\nThis website is built using [Docusaurus](https://docusaurus.io/), a modern static website generator.\\n\\n## Contributing to the `docs` Folder\\n\\nThis guide is for contributors looking to make changes to the documentation in the `dspy/docs` folder. \\n\\n1. **Pull the up-to-date version of the website**: Please pull the latest version of the live documentation site via its subtree repository with the following command:\\n\\n```bash\\n#Ensure you are in the top-level dspy/ folder\\ngit subtree pull --prefix=docs https://github.com/krypticmouse/dspy-docs master\\n```\\n\\n2. **Push your new changes on a new branch**: Feel free to add or edit existing documentation and open a PR for your changes. Once your PR is reviewed and approved, the changes will be ready to merge into main. \\n\\n3. **Updating the website**: Once your changes are merged to main, they need to be pushed to the subtree repository that hosts the live documentation site. This step will eventually be done automatically, but for now, please run the following command to push the updated `docs` content to the website subtree repository:\\n\\n```bash\\n#Ensure you are in the top-level dspy/ folder\\ngit subtree push --prefix=docs https://github.com/krypticmouse/dspy-docs master\\n```\\n',\n",
       " '---\\nsidebar_position: 7\\n---\\n\\n# DSPy Assertions\\n\\nLanguage models (LMs) have transformed how we interact with machine learning, offering vast capabilities in natural language understanding and generation. However, ensuring these models adhere to domain-specific constraints remains a challenge. Despite the growth of techniques like fine-tuning or “prompt engineering”, these approaches are extremely tedious and rely on heavy, manual hand-waving to guide the LMs in adhering to specific constraints. Even DSPy\\'s modularity of programming prompting pipelines lacks mechanisms to effectively and automatically enforce these constraints. \\n\\nTo address this, we introduce DSPy Assertions, a feature within the DSPy framework designed to automate the enforcement of computational constraints on LMs. DSPy Assertions empower developers to guide LMs towards desired outcomes with minimal manual intervention, enhancing the reliability, predictability, and correctness of LM outputs.\\n\\n## dspy.Assert and dspy.Suggest API\\n\\nWe introduce two primary constructs within DSPy Assertions:\\n\\n- **`dspy.Assert`**:\\n  - **Parameters**: \\n    - `constraint (bool)`: Outcome of Python-defined boolean validation check.\\n    - `msg (Optional[str])`: User-defined error message providing feedback or correction guidance.\\n    - `backtrack (Optional[module])`: Specifies target module for retry attempts upon constraint failure. The default backtracking module is the last module before the assertion.\\n  - **Behavior**: Initiates retry  upon failure, dynamically adjusting the pipeline\\'s execution. If failures persist, it halts execution and raises a `dspy.AssertionError`.\\n\\n- **`dspy.Suggest`**:\\n  - **Parameters**: Similar to `dspy.Assert`.\\n  - **Behavior**: Encourages self-refinement through retries without enforcing hard stops. Logs failures after maximum backtracking attempts and continues execution.\\n\\n- **dspy.Assert vs. Python Assertions**: Unlike conventional Python `assert` statements that terminate the program upon failure, `dspy.Assert` conducts a sophisticated retry mechanism, allowing the pipeline to adjust. \\n\\nSpecifically, when a constraint is not met:\\n\\n- Backtracking Mechanism: An under-the-hood backtracking is initiated, offering the model a chance to self-refine and proceed, which is done through\\n- Dynamic Signature Modification: internally modifying your DSPy program’s Signature by adding the following fields:\\n    - Past Output: your model\\'s past output that did not pass the validation_fn\\n    - Instruction: your user-defined feedback message on what went wrong and what possibly to fix\\n\\nIf the error continues past the `max_backtracking_attempts`, then `dspy.Assert` will halt the pipeline execution, altering you with an `dspy.AssertionError`. This ensures your program doesn\\'t continue executing with “bad” LM behavior and immediately highlights sample failure outputs for user assessment. \\n\\n- **dspy.Suggest vs. dspy.Assert**: `dspy.Suggest` on the other hand offers a softer approach. It maintains the same retry backtracking as `dspy.Assert` but instead serves as a gentle nudger. If the model outputs cannot pass the model constraints after the `max_backtracking_attempts`, `dspy.Suggest` will log the persistent failure and continue execution of the program on the rest of the data. This ensures the LM pipeline works in a \"best-effort\" manner without halting execution. \\n\\n- **`dspy.Suggest`** are best utilized as \"helpers\" during the evaluation phase, offering guidance and potential corrections without halting the pipeline.\\n- **`dspy.Assert`** are recommended during the development stage as \"checkers\" to ensure the LM behaves as expected, providing a robust mechanism for identifying and addressing errors early in the development cycle.\\n\\n\\n## Use Case: Including Assertions in DSPy Programs\\n\\nWe start with using an example of a multi-hop QA SimplifiedBaleen pipeline as defined in the intro walkthrough. \\n\\n```python\\nclass SimplifiedBaleen(dspy.Module):\\n    def __init__(self, passages_per_hop=2, max_hops=2):\\n        super().__init__()\\n\\n        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\\n        self.retrieve = dspy.Retrieve(k=passages_per_hop)\\n        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\\n        self.max_hops = max_hops\\n\\n    def forward(self, question):\\n        context = []\\n        prev_queries = [question]\\n\\n        for hop in range(self.max_hops):\\n            query = self.generate_query[hop](context=context, question=question).query\\n            prev_queries.append(query)\\n            passages = self.retrieve(query).passages\\n            context = deduplicate(context + passages)\\n        \\n        pred = self.generate_answer(context=context, question=question)\\n        pred = dspy.Prediction(context=context, answer=pred.answer)\\n        return pred\\n\\nbaleen = SimplifiedBaleen()\\n\\nbaleen(question = \"Which award did Gary Zukav\\'s first book receive?\")\\n```\\n\\nTo include DSPy Assertions, we simply define our validation functions and declare our assertions following the respective model generation. \\n\\nFor this use case, suppose we want to impose the following constraints:\\n    1. Length - each query should be less than 100 characters\\n    2. Uniqueness - each generated query should differ from previously-generated queries. \\n    \\nWe can define these validation checks as boolean functions:\\n\\n```python\\n#simplistic boolean check for query length\\nlen(query) <= 100\\n\\n#Python function for validating distinct queries\\ndef validate_query_distinction_local(previous_queries, query):\\n    \"\"\"check if query is distinct from previous queries\"\"\"\\n    if previous_queries == []:\\n        return True\\n    if dspy.evaluate.answer_exact_match_str(query, previous_queries, frac=0.8):\\n        return False\\n    return True\\n```\\n\\nWe can declare these validation checks through `dspy.Suggest` statements (as we want to test the program in a best-effort demonstration). We want to keep these after the query generation `query = self.generate_query[hop](context=context, question=question).query`.\\n\\n```python\\ndspy.Suggest(\\n    len(query) <= 100,\\n    \"Query should be short and less than 100 characters\",\\n)\\n\\ndspy.Suggest(\\n    validate_query_distinction_local(prev_queries, query),\\n    \"Query should be distinct from: \"\\n    + \"; \".join(f\"{i+1}) {q}\" for i, q in enumerate(prev_queries)),\\n)\\n```\\n\\nIt is recommended to define a program with assertions separately than your original program if you are doing comparative evaluation for the effect of assertions. If not, feel free to set Assertions away!\\n\\nLet\\'s take a look at how the SimplifiedBaleen program will look with Assertions included:\\n\\n```python\\nclass SimplifiedBaleenAssertions(dspy.Module):\\n    def __init__(self, passages_per_hop=2, max_hops=2):\\n        super().__init__()\\n        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\\n        self.retrieve = dspy.Retrieve(k=passages_per_hop)\\n        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\\n        self.max_hops = max_hops\\n\\n    def forward(self, question):\\n        context = []\\n        prev_queries = [question]\\n\\n        for hop in range(self.max_hops):\\n            query = self.generate_query[hop](context=context, question=question).query\\n\\n            dspy.Suggest(\\n                len(query) <= 100,\\n                \"Query should be short and less than 100 characters\",\\n            )\\n\\n            dspy.Suggest(\\n                validate_query_distinction_local(prev_queries, query),\\n                \"Query should be distinct from: \"\\n                + \"; \".join(f\"{i+1}) {q}\" for i, q in enumerate(prev_queries)),\\n            )\\n\\n            prev_queries.append(query)\\n            passages = self.retrieve(query).passages\\n            context = deduplicate(context + passages)\\n        \\n        if all_queries_distinct(prev_queries):\\n            self.passed_suggestions += 1\\n\\n        pred = self.generate_answer(context=context, question=question)\\n        pred = dspy.Prediction(context=context, answer=pred.answer)\\n        return pred\\n```\\n\\nNow calling programs with DSPy Assertions requires one last step, and that is transforming the program to wrap it with internal assertions backtracking and Retry logic. \\n\\n```python\\nfrom dspy.primitives.assertions import assert_transform_module, backtrack_handler\\n\\nbaleen_with_assertions = assert_transform_module(SimplifiedBaleenAssertions(), backtrack_handler)\\n\\n# backtrack_handler is parameterized over a few settings for the backtracking mechanism\\n# To change the number of max retry attempts, you can do\\nbaleen_with_assertions_retry_once = assert_transform_module(SimplifiedBaleenAssertions(), \\n    functools.partial(backtrack_handler, max_backtracks=1))\\n```\\n\\nAlternatively, you can also directly call `activate_assertions` on the program with `dspy.Assert/Suggest` statements using the default backtracking mechanism (`max_backtracks=2`):\\n\\n```python\\nbaleen_with_assertions = SimplifiedBaleenAssertions().activate_assertions()\\n```\\n\\nNow let\\'s take a look at the internal LM backtracking by inspecting the history of the LM query generations. Here we see that when a query fails to pass the validation check of being less than 100 characters, its internal `GenerateSearchQuery` signature is dynamically modified during the backtracking+Retry process to include the past query and the corresponding user-defined instruction: `\"Query should be short and less than 100 characters\"`.\\n\\n\\n```\\nWrite a simple search query that will help answer a complex question.\\n\\n---\\n\\nFollow the following format.\\n\\nContext: may contain relevant facts\\n\\nQuestion: ${question}\\n\\nReasoning: Let\\'s think step by step in order to ${produce the query}. We ...\\n\\nQuery: ${query}\\n\\n---\\n\\nContext:\\n[1] «Kerry Condon | Kerry Condon (born 4 January 1983) is [...]»\\n[2] «Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was [...]»\\n\\nQuestion: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\\n\\nReasoning: Let\\'s think step by step in order to find the answer to this question. First, we need to identify the actress who played Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" Then, we need to find out if this actress also acted in the short film \"The Shore.\"\\n\\nQuery: \"actress who played Ophelia in Royal Shakespeare Company production of Hamlet\" + \"actress in short film The Shore\"\\n\\n\\n\\nWrite a simple search query that will help answer a complex question.\\n\\n---\\n\\nFollow the following format.\\n\\nContext: may contain relevant facts\\n\\nQuestion: ${question}\\n\\nPast Query: past output with errors\\n\\nInstructions: Some instructions you must satisfy\\n\\nQuery: ${query}\\n\\n---\\n\\nContext:\\n[1] «Kerry Condon | Kerry Condon (born 4 January 1983) is an Irish television and film actress, best known for her role as Octavia of the Julii in the HBO/BBC series \"Rome,\" as Stacey Ehrmantraut in AMC\\'s \"Better Call Saul\" and as the voice of F.R.I.D.A.Y. in various films in the Marvel Cinematic Universe. She is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"»\\n[2] «Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was an Italian born American actress who had a brief Broadway stage career before leaving to become a wife and mother. Born in Naples she came to acting in 1894 playing a Mexican girl in a play at the Empire Theatre. Wilson Barrett engaged her for a role in his play \"The Sign of the Cross\" which he took on tour of the United States. Riccardo played the role of Ancaria and later played Berenice in the same play. Robert B. Mantell in 1898 who struck by her beauty also cast her in two Shakespeare plays, \"Romeo and Juliet\" and \"Othello\". Author Lewis Strang writing in 1899 said Riccardo was the most promising actress in America at the time. Towards the end of 1898 Mantell chose her for another Shakespeare part, Ophelia im Hamlet. Afterwards she was due to join Augustin Daly\\'s Theatre Company but Daly died in 1899. In 1899 she gained her biggest fame by playing Iras in the first stage production of Ben-Hur.»\\n\\nQuestion: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\\n\\nPast Query: \"actress who played Ophelia in Royal Shakespeare Company production of Hamlet\" + \"actress in short film The Shore\"\\n\\nInstructions: Query should be short and less than 100 characters\\n\\nQuery: \"actress Ophelia RSC Hamlet\" + \"actress The Shore\"\\n\\n```\\n\\n\\n## Assertion-Driven Optimizations\\n\\nDSPy Assertions work with optimizations that DSPy offers, particularly with `BootstrapFewShotWithRandomSearch`, including the following settings:\\n\\n- Compilation with Assertions\\n    This includes assertion-driven example bootstrapping and counterexample bootstrapping during compilation. The teacher model for bootstrapping few-shot demonstrations can make use of DSPy Assertions to offer robust bootstrapped examples for the student model to learn from during inference. In this setting, the student model does not perform assertion aware optimizations (backtracking and retry) during inference.\\n- Compilation + Inference with Assertions\\n    -This includes assertion-driven optimizations in both compilation and inference. Now the teacher model offers assertion-driven examples but the student can further optimize with assertions of its own during inference time. \\n```python\\nteleprompter = BootstrapFewShotWithRandomSearch(\\n    metric=validate_context_and_answer_and_hops,\\n    max_bootstrapped_demos=max_bootstrapped_demos,\\n    num_candidate_programs=6,\\n)\\n\\n#Compilation with Assertions\\ncompiled_with_assertions_baleen = teleprompter.compile(student = baleen, teacher = baleen_with_assertions, trainset = trainset, valset = devset)\\n\\n#Compilation + Inference with Assertions\\ncompiled_baleen_with_assertions = teleprompter.compile(student=baleen_with_assertions, teacher = baleen_with_assertions, trainset=trainset, valset=devset)\\n\\n```',\n",
       " \"---\\nsidebar_position: 1\\n---\\n\\n# API References\\n\\nWelcome to the API References for DSPy! This is where you'll find easy-to-understand information about all the parts of DSPy that you can use in your projects. We've got guides on different tools and helpers that DSPy has, like modules and optimizers. Everything is sorted so you can quickly find what you need. If you're making something and need to quickly get started with DSPy to do certain tasks, this place will show you how to set it up and get it working just right.\",\n",
       " '---\\nsidebar_position: 9\\n---\\n\\n# dsp.Mistral\\n\\n### Usage\\n\\n```python\\nlm = dsp.Mistral(model=\\'mistral-medium-latest\\', api_key=\"your-mistralai-api-key\")\\n```\\n\\n### Constructor\\n\\nThe constructor initializes the base class `LM` and verifies the `api_key` provided or defined through the `MISTRAL_API_KEY` environment variable.\\n\\n```python\\nclass Mistral(LM):\\n    def __init__(\\n        self,\\n        model: str = \"mistral-medium-latest\",\\n        api_key: Optional[str] = None,\\n        **kwargs,\\n    ):\\n```\\n\\n**Parameters:**\\n- `model` (_str_): Mistral AI pretrained models. Defaults to `mistral-medium-latest`.\\n- `api_key` (_Optional[str]_, _optional_): API provider from Mistral AI. Defaults to None.\\n- `**kwargs`: Additional language model arguments to pass to the API provider.\\n\\n### Methods\\n\\nRefer to [`dspy.Mistral`](#) documentation.\\n',\n",
       " '---\\nsidebar_position: 8\\n---\\n\\n# dspy.Databricks\\n\\n### Usage\\n```python\\nlm = dspy.Databricks(model=\"databricks-mpt-30b-instruct\")\\n```\\n\\n### Constructor\\n\\nThe constructor inherits from the `GPT3` class and verifies the Databricks authentication credentials for using Databricks Model Serving API through the OpenAI SDK.\\nWe expect the following environment variables to be set:\\n- `openai.api_key`: Databricks API key.\\n- `openai.base_url`: Databricks Model Endpoint url\\n\\nThe `kwargs` attribute is initialized with default values for relevant text generation parameters needed for communicating with the Databricks OpenAI SDK, such as `temperature`, `max_tokens`, `top_p`, and `n`. However, it removes the `frequency_penalty` and `presence_penalty` arguments as these are not currently supported by the Databricks API.\\n\\n```python\\nclass Databricks(GPT3):\\n    def __init__(\\n        self,\\n        model: str,\\n        api_key: Optional[str] = None,\\n        api_base: Optional[str] = None,\\n        model_type: Literal[\"chat\", \"text\"] = None,\\n        **kwargs,\\n    ):\\n```\\n\\n**Parameters:**\\n- `model` (_str_): models hosted on Databricks.\\n- `stop` (_List[str]_, _optional_): List of stopping tokens to end generation.\\n- `api_key` (_Optional[str]_): Databricks API key. Defaults to None\\n- `api_base` (_Optional[str]_): Databricks Model Endpoint url Defaults to None.\\n- `model_type` (_Literal[\"chat\", \"text\", \"embeddings\"]_): Specified model type to use.\\n- `**kwargs`: Additional language model arguments to pass to the API provider.\\n\\n### Methods\\n\\nRefer to [`dspy.OpenAI`](https://dspy-docs.vercel.app/api/language_model_clients/OpenAI) documentation.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
